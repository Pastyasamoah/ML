{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# FIFA 1 DATASET CLEANING CHALLENGE\n",
    "\n",
    "### Presented by Pasty Asamoah, Ghana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hello world, let's begin!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# numerical python modules\n",
    "import numpy as np\n",
    "\n",
    "# pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# regular expressions module\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the data into pandas dataframes stored as df\n",
    "\n",
    "df = pd.read_csv(\"fifa_1.csv\" ,low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  18979\n",
      "Columns:  77\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# know your data\n",
    "# Looking at the number of rows and columns in the dataset\n",
    "\n",
    "rows, columns = df.shape\n",
    "\n",
    "print(\"Rows: \", rows)\n",
    "\n",
    "print(\"Columns: \",columns)\n",
    "\n",
    "# there are 18,979 rows in the dataset with 77 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoUrl</th>\n",
       "      <th>LongName</th>\n",
       "      <th>playerUrl</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>↓OVA</th>\n",
       "      <th>POT</th>\n",
       "      <th>Team &amp; Contract</th>\n",
       "      <th>...</th>\n",
       "      <th>A/W</th>\n",
       "      <th>D/W</th>\n",
       "      <th>IR</th>\n",
       "      <th>PAC</th>\n",
       "      <th>SHO</th>\n",
       "      <th>PAS</th>\n",
       "      <th>DRI</th>\n",
       "      <th>DEF</th>\n",
       "      <th>PHY</th>\n",
       "      <th>Hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://cdn.sofifa.com/players/158/023/21_60.png</td>\n",
       "      <td>Lionel Messi</td>\n",
       "      <td>http://sofifa.com/player/158023/lionel-messi/2...</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>RW ST CF</td>\n",
       "      <td>L. Messi</td>\n",
       "      <td>33</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>\\n\\n\\n\\nFC Barcelona\\n2004 ~ 2021\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>5 ★</td>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>\\n372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cdn.sofifa.com/players/020/801/21_60.png</td>\n",
       "      <td>C. Ronaldo dos Santos Aveiro</td>\n",
       "      <td>http://sofifa.com/player/20801/c-ronaldo-dos-s...</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>ST LW</td>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>35</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>\\n\\n\\n\\nJuventus\\n2018 ~ 2022\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>5 ★</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "      <td>35</td>\n",
       "      <td>77</td>\n",
       "      <td>\\n344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           photoUrl  \\\n",
       "0  https://cdn.sofifa.com/players/158/023/21_60.png   \n",
       "1  https://cdn.sofifa.com/players/020/801/21_60.png   \n",
       "\n",
       "                       LongName  \\\n",
       "0                  Lionel Messi   \n",
       "1  C. Ronaldo dos Santos Aveiro   \n",
       "\n",
       "                                           playerUrl Nationality Positions  \\\n",
       "0  http://sofifa.com/player/158023/lionel-messi/2...   Argentina  RW ST CF   \n",
       "1  http://sofifa.com/player/20801/c-ronaldo-dos-s...    Portugal     ST LW   \n",
       "\n",
       "                Name  Age  ↓OVA  POT                        Team & Contract  \\\n",
       "0           L. Messi   33    93   93  \\n\\n\\n\\nFC Barcelona\\n2004 ~ 2021\\n\\n   \n",
       "1  Cristiano Ronaldo   35    92   92      \\n\\n\\n\\nJuventus\\n2018 ~ 2022\\n\\n   \n",
       "\n",
       "   ...     A/W  D/W   IR PAC  SHO PAS  DRI DEF PHY   Hits  \n",
       "0  ...  Medium  Low  5 ★  85   92  91   95  38  65  \\n372  \n",
       "1  ...    High  Low  5 ★  89   93  81   89  35  77  \\n344  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Taking a snapshot of the data\n",
    "# Looking at the first 2 rows in the dataset\n",
    "\n",
    "df.head(2)\n",
    "\n",
    "# the data looks messy at first glance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check if there are duplicates.\n",
    "# if there are, drop them and replace the values in the data set.\n",
    "\n",
    "if df.duplicated().any() == True:\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['photoUrl', 'LongName', 'playerUrl', 'Nationality', 'Positions', 'Name',\n",
       "       'Age', '↓OVA', 'POT', 'Team & Contract', 'ID', 'Height', 'Weight',\n",
       "       'foot', 'BOV', 'BP', 'Growth', 'Joined', 'Loan Date End', 'Value',\n",
       "       'Wage', 'Release Clause', 'Attacking', 'Crossing', 'Finishing',\n",
       "       'Heading Accuracy', 'Short Passing', 'Volleys', 'Skill', 'Dribbling',\n",
       "       'Curve', 'FK Accuracy', 'Long Passing', 'Ball Control', 'Movement',\n",
       "       'Acceleration', 'Sprint Speed', 'Agility', 'Reactions', 'Balance',\n",
       "       'Power', 'Shot Power', 'Jumping', 'Stamina', 'Strength', 'Long Shots',\n",
       "       'Mentality', 'Aggression', 'Interceptions', 'Positioning', 'Vision',\n",
       "       'Penalties', 'Composure', 'Defending', 'Marking', 'Standing Tackle',\n",
       "       'Sliding Tackle', 'Goalkeeping', 'GK Diving', 'GK Handling',\n",
       "       'GK Kicking', 'GK Positioning', 'GK Reflexes', 'Total Stats',\n",
       "       'Base Stats', 'W/F', 'SM', 'A/W', 'D/W', 'IR', 'PAC', 'SHO', 'PAS',\n",
       "       'DRI', 'DEF', 'PHY', 'Hits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Since some of the columns were not visible, it is necessary to take a look at the table column names\n",
    "# Looking at the table columns\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rename the col ↓OVA to OVA\n",
    "\n",
    "df.rename(columns={'↓OVA':'OVA'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the datatypes to determine which columns needs much attention\n",
    "# Most often, integer columns that report \"object\" as datatypes have issues\n",
    "# Lets dynamically check the data types\n",
    "\n",
    "# Keep track of all integer columns. \n",
    "integer_columns = []\n",
    "\n",
    "# Keep track of all string columns. \n",
    "string_columns = []\n",
    "\n",
    "# Keep track of all object columns. We will focus more on this\n",
    "other_columns = []\n",
    "\n",
    "# Lets loop through the columns and check the data types of the values in there\n",
    "\n",
    "for col in df.columns: \n",
    "    \n",
    "    if df[col].dtype==\"int64\": # checks for integers\n",
    "        integer_columns.append(col) \n",
    "        \n",
    "    elif df[col].dtype==\"object\": # checks for objects\n",
    "        other_columns.append(col) \n",
    "        \n",
    "    elif df[col].dtype==\"str\": # checks for str\n",
    "        string_columns.append(col) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'OVA', 'POT', 'ID', 'BOV', 'Growth', 'Attacking', 'Crossing', 'Finishing', 'Heading Accuracy', 'Short Passing', 'Volleys', 'Skill', 'Dribbling', 'Curve', 'FK Accuracy', 'Long Passing', 'Ball Control', 'Movement', 'Acceleration', 'Sprint Speed', 'Agility', 'Reactions', 'Balance', 'Power', 'Shot Power', 'Jumping', 'Stamina', 'Strength', 'Long Shots', 'Mentality', 'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure', 'Defending', 'Marking', 'Standing Tackle', 'Sliding Tackle', 'Goalkeeping', 'GK Diving', 'GK Handling', 'GK Kicking', 'GK Positioning', 'GK Reflexes', 'Total Stats', 'Base Stats', 'PAC', 'SHO', 'PAS', 'DRI', 'DEF', 'PHY']\n",
      "Count:  55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets look at the integer columns\n",
    "\n",
    "print(integer_columns)\n",
    "\n",
    "print(\"Count: \", len(integer_columns))\n",
    "\n",
    "# 55 columns are integers. There are less issues here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['photoUrl', 'LongName', 'playerUrl', 'Nationality', 'Positions', 'Name', 'Team & Contract', 'Height', 'Weight', 'foot', 'BP', 'Joined', 'Loan Date End', 'Value', 'Wage', 'Release Clause', 'W/F', 'SM', 'A/W', 'D/W', 'IR', 'Hits']\n",
      "Count:  22\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the object columns\n",
    "\n",
    "print(other_columns)\n",
    "\n",
    "print(\"Count: \", len(other_columns))\n",
    "\n",
    "# 22 columns are objects. There are less issues here\n",
    "# Note that, since we have 77 columns, if 55 are integer columns and 22 are objects, then no columns were fully string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Note that, since we have 77 columns, if 55 are integer columns and 22 are objects, then no columns were fully string\n",
    "\n",
    "len(integer_columns) + len(other_columns) == df.shape[1]\n",
    "\n",
    "# we have True, meaning we don't have any string column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 int64\n",
       "OVA                 int64\n",
       "POT                 int64\n",
       "ID                  int64\n",
       "BOV                 int64\n",
       "Growth              int64\n",
       "Attacking           int64\n",
       "Crossing            int64\n",
       "Finishing           int64\n",
       "Heading Accuracy    int64\n",
       "Short Passing       int64\n",
       "Volleys             int64\n",
       "Skill               int64\n",
       "Dribbling           int64\n",
       "Curve               int64\n",
       "FK Accuracy         int64\n",
       "Long Passing        int64\n",
       "Ball Control        int64\n",
       "Movement            int64\n",
       "Acceleration        int64\n",
       "Sprint Speed        int64\n",
       "Agility             int64\n",
       "Reactions           int64\n",
       "Balance             int64\n",
       "Power               int64\n",
       "Shot Power          int64\n",
       "Jumping             int64\n",
       "Stamina             int64\n",
       "Strength            int64\n",
       "Long Shots          int64\n",
       "Mentality           int64\n",
       "Aggression          int64\n",
       "Interceptions       int64\n",
       "Positioning         int64\n",
       "Vision              int64\n",
       "Penalties           int64\n",
       "Composure           int64\n",
       "Defending           int64\n",
       "Marking             int64\n",
       "Standing Tackle     int64\n",
       "Sliding Tackle      int64\n",
       "Goalkeeping         int64\n",
       "GK Diving           int64\n",
       "GK Handling         int64\n",
       "GK Kicking          int64\n",
       "GK Positioning      int64\n",
       "GK Reflexes         int64\n",
       "Total Stats         int64\n",
       "Base Stats          int64\n",
       "PAC                 int64\n",
       "SHO                 int64\n",
       "PAS                 int64\n",
       "DRI                 int64\n",
       "DEF                 int64\n",
       "PHY                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets examine the integer columns as a group\n",
    "# Check for missing values\n",
    "\n",
    "df[integer_columns].isna().any()\n",
    "df[integer_columns].isnull().any()\n",
    "\n",
    "# we don't have any missing value\n",
    "# lets look at the data types\n",
    "\n",
    "df[integer_columns].dtypes\n",
    "\n",
    "# they are all integers. It means all these columns are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>OVA</th>\n",
       "      <th>POT</th>\n",
       "      <th>ID</th>\n",
       "      <th>BOV</th>\n",
       "      <th>Growth</th>\n",
       "      <th>Attacking</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>Finishing</th>\n",
       "      <th>Heading Accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>GK Positioning</th>\n",
       "      <th>GK Reflexes</th>\n",
       "      <th>Total Stats</th>\n",
       "      <th>Base Stats</th>\n",
       "      <th>PAC</th>\n",
       "      <th>SHO</th>\n",
       "      <th>PAS</th>\n",
       "      <th>DRI</th>\n",
       "      <th>DEF</th>\n",
       "      <th>PHY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "      <td>18978.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.194225</td>\n",
       "      <td>65.718042</td>\n",
       "      <td>71.135789</td>\n",
       "      <td>226403.457477</td>\n",
       "      <td>66.751080</td>\n",
       "      <td>5.417747</td>\n",
       "      <td>248.935610</td>\n",
       "      <td>49.687375</td>\n",
       "      <td>45.842871</td>\n",
       "      <td>51.941459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.217620</td>\n",
       "      <td>16.519654</td>\n",
       "      <td>1595.272368</td>\n",
       "      <td>355.699652</td>\n",
       "      <td>67.453683</td>\n",
       "      <td>53.457582</td>\n",
       "      <td>57.680472</td>\n",
       "      <td>62.874750</td>\n",
       "      <td>49.864738</td>\n",
       "      <td>64.368427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.710618</td>\n",
       "      <td>6.968701</td>\n",
       "      <td>6.114189</td>\n",
       "      <td>27141.767404</td>\n",
       "      <td>6.746785</td>\n",
       "      <td>5.663967</td>\n",
       "      <td>74.300567</td>\n",
       "      <td>18.131089</td>\n",
       "      <td>19.567492</td>\n",
       "      <td>17.293983</td>\n",
       "      <td>...</td>\n",
       "      <td>17.002582</td>\n",
       "      <td>17.854549</td>\n",
       "      <td>269.874424</td>\n",
       "      <td>40.760683</td>\n",
       "      <td>10.678065</td>\n",
       "      <td>13.827581</td>\n",
       "      <td>10.081845</td>\n",
       "      <td>9.927607</td>\n",
       "      <td>16.442378</td>\n",
       "      <td>9.601882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>210134.500000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>232421.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1627.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>246922.750000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>259216.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age           OVA           POT             ID           BOV  \\\n",
       "count  18978.000000  18978.000000  18978.000000   18978.000000  18978.000000   \n",
       "mean      25.194225     65.718042     71.135789  226403.457477     66.751080   \n",
       "std        4.710618      6.968701      6.114189   27141.767404      6.746785   \n",
       "min       16.000000     47.000000     47.000000      41.000000     48.000000   \n",
       "25%       21.000000     61.000000     67.000000  210134.500000     62.000000   \n",
       "50%       25.000000     66.000000     71.000000  232421.000000     67.000000   \n",
       "75%       29.000000     70.000000     75.000000  246922.750000     71.000000   \n",
       "max       53.000000     93.000000     95.000000  259216.000000     93.000000   \n",
       "\n",
       "             Growth     Attacking      Crossing     Finishing  \\\n",
       "count  18978.000000  18978.000000  18978.000000  18978.000000   \n",
       "mean       5.417747    248.935610     49.687375     45.842871   \n",
       "std        5.663967     74.300567     18.131089     19.567492   \n",
       "min        0.000000     42.000000      6.000000      3.000000   \n",
       "25%        0.000000    222.000000     38.000000     30.000000   \n",
       "50%        4.000000    263.000000     54.000000     49.000000   \n",
       "75%        9.000000    297.000000     63.000000     62.000000   \n",
       "max       26.000000    437.000000     94.000000     95.000000   \n",
       "\n",
       "       Heading Accuracy  ...  GK Positioning   GK Reflexes   Total Stats  \\\n",
       "count      18978.000000  ...    18978.000000  18978.000000  18978.000000   \n",
       "mean          51.941459  ...       16.217620     16.519654   1595.272368   \n",
       "std           17.293983  ...       17.002582     17.854549    269.874424   \n",
       "min            5.000000  ...        2.000000      2.000000    747.000000   \n",
       "25%           44.000000  ...        8.000000      8.000000   1452.000000   \n",
       "50%           55.000000  ...       11.000000     11.000000   1627.000000   \n",
       "75%           64.000000  ...       14.000000     14.000000   1781.000000   \n",
       "max           93.000000  ...       91.000000     90.000000   2316.000000   \n",
       "\n",
       "         Base Stats           PAC           SHO           PAS           DRI  \\\n",
       "count  18978.000000  18978.000000  18978.000000  18978.000000  18978.000000   \n",
       "mean     355.699652     67.453683     53.457582     57.680472     62.874750   \n",
       "std       40.760683     10.678065     13.827581     10.081845      9.927607   \n",
       "min      232.000000     25.000000     16.000000     25.000000     25.000000   \n",
       "25%      327.000000     61.000000     44.000000     51.000000     57.000000   \n",
       "50%      356.000000     68.000000     56.000000     58.000000     64.000000   \n",
       "75%      384.000000     75.000000     64.000000     64.000000     69.000000   \n",
       "max      498.000000     96.000000     93.000000     93.000000     95.000000   \n",
       "\n",
       "                DEF           PHY  \n",
       "count  18978.000000  18978.000000  \n",
       "mean      49.864738     64.368427  \n",
       "std       16.442378      9.601882  \n",
       "min       12.000000     28.000000  \n",
       "25%       35.000000     58.000000  \n",
       "50%       53.000000     65.000000  \n",
       "75%       63.000000     71.000000  \n",
       "max       91.000000     91.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets zoom in to describe our data.\n",
    "\n",
    "df[integer_columns].describe()\n",
    "\n",
    "# You can do df[integer_columns].describe().T to transpose the output\n",
    "# You can see that we don't have negative values or problematic values in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets create a new dataframe and keep all cleaned columns in it.\n",
    "# I will name it clean_data\n",
    "\n",
    "clean_data = df[integer_columns].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoUrl</th>\n",
       "      <th>LongName</th>\n",
       "      <th>playerUrl</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team &amp; Contract</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>foot</th>\n",
       "      <th>...</th>\n",
       "      <th>Loan Date End</th>\n",
       "      <th>Value</th>\n",
       "      <th>Wage</th>\n",
       "      <th>Release Clause</th>\n",
       "      <th>W/F</th>\n",
       "      <th>SM</th>\n",
       "      <th>A/W</th>\n",
       "      <th>D/W</th>\n",
       "      <th>IR</th>\n",
       "      <th>Hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>...</td>\n",
       "      <td>1013</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "      <td>18978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18978</td>\n",
       "      <td>18851</td>\n",
       "      <td>18978</td>\n",
       "      <td>164</td>\n",
       "      <td>640</td>\n",
       "      <td>17919</td>\n",
       "      <td>9023</td>\n",
       "      <td>21</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>214</td>\n",
       "      <td>141</td>\n",
       "      <td>1216</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://cdn.sofifa.com/players/235/103/21_60.png</td>\n",
       "      <td>Liam Kelly</td>\n",
       "      <td>http://sofifa.com/player/238892/martin-peralta...</td>\n",
       "      <td>England</td>\n",
       "      <td>CB</td>\n",
       "      <td>J. Rodríguez</td>\n",
       "      <td>\\n India\\nFree\\n\\n</td>\n",
       "      <td>6'0\"</td>\n",
       "      <td>154lbs</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>Jun 30, 2021</td>\n",
       "      <td>€1.1M</td>\n",
       "      <td>€2K</td>\n",
       "      <td>€0</td>\n",
       "      <td>3 ★</td>\n",
       "      <td>2★</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1 ★</td>\n",
       "      <td>\\n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1704</td>\n",
       "      <td>2441</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>2859</td>\n",
       "      <td>1496</td>\n",
       "      <td>14444</td>\n",
       "      <td>...</td>\n",
       "      <td>770</td>\n",
       "      <td>467</td>\n",
       "      <td>2997</td>\n",
       "      <td>1261</td>\n",
       "      <td>11694</td>\n",
       "      <td>9142</td>\n",
       "      <td>12700</td>\n",
       "      <td>13955</td>\n",
       "      <td>17628</td>\n",
       "      <td>4321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                photoUrl    LongName  \\\n",
       "count                                              18978       18978   \n",
       "unique                                             18978       18851   \n",
       "top     https://cdn.sofifa.com/players/235/103/21_60.png  Liam Kelly   \n",
       "freq                                                   1           3   \n",
       "\n",
       "                                                playerUrl Nationality  \\\n",
       "count                                               18978       18978   \n",
       "unique                                              18978         164   \n",
       "top     http://sofifa.com/player/238892/martin-peralta...     England   \n",
       "freq                                                    1        1704   \n",
       "\n",
       "       Positions          Name     Team & Contract Height  Weight   foot  ...  \\\n",
       "count      18978         18978               18978  18978   18978  18978  ...   \n",
       "unique       640         17919                9023     21      56      2  ...   \n",
       "top           CB  J. Rodríguez  \\n India\\nFree\\n\\n   6'0\"  154lbs  Right  ...   \n",
       "freq        2441            13                  29   2859    1496  14444  ...   \n",
       "\n",
       "       Loan Date End  Value   Wage Release Clause    W/F     SM     A/W  \\\n",
       "count           1013  18978  18978          18978  18978  18978   18978   \n",
       "unique            24    214    141           1216      5      5       3   \n",
       "top     Jun 30, 2021  €1.1M    €2K             €0    3 ★     2★  Medium   \n",
       "freq             770    467   2997           1261  11694   9142   12700   \n",
       "\n",
       "           D/W     IR   Hits  \n",
       "count    18978  18978  18978  \n",
       "unique       3      5    374  \n",
       "top     Medium    1 ★    \\n1  \n",
       "freq     13955  17628   4321  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Now lets handle the object columns\n",
    "# Lets take a look at it.\n",
    "# Remember we have 22 columns to clean\n",
    "\n",
    "df[other_columns].describe()\n",
    "\n",
    "# These columns are really messy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because these columns are messy, lets define a columns that return the unique characters in each field.\n",
    "# With that, we can identify foreign characters and deal with them\n",
    "# The function accepts two arguments: the data frame and the column in question\n",
    "\n",
    "def get_unique_characters_in( df, column ):\n",
    "    result = []\n",
    "    for index, row in df.iterrows():\n",
    "        for char in row[column]:\n",
    "            if char not in result:\n",
    "                result.append(char)\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 't', 'p', 's', ':', '/', 'c', 'd', 'n', '.', 'o', 'f', 'i', 'a', 'm', 'l', 'y', 'e', 'r', '1', '5', '8', '0', '2', '3', '_', '6', 'g', '9', '7', '4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets check all the unique values in the photoUrl column\n",
    "\n",
    "print(get_unique_characters_in(df, 'photoUrl'))\n",
    "\n",
    "# we don't have any strange character in it, Just URL related characters. That means, we're good to go!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    https://cdn.sofifa.com/players/158/023/21_60.png\n",
       "1    https://cdn.sofifa.com/players/020/801/21_60.png\n",
       "2    https://cdn.sofifa.com/players/200/389/21_60.png\n",
       "3    https://cdn.sofifa.com/players/192/985/21_60.png\n",
       "4    https://cdn.sofifa.com/players/190/871/21_60.png\n",
       "5    https://cdn.sofifa.com/players/188/545/21_60.png\n",
       "6    https://cdn.sofifa.com/players/231/747/21_60.png\n",
       "7    https://cdn.sofifa.com/players/212/831/21_60.png\n",
       "8    https://cdn.sofifa.com/players/209/331/21_60.png\n",
       "9    https://cdn.sofifa.com/players/208/722/21_60.png\n",
       "Name: photoUrl, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets handle the photoUrl column\n",
    "# Check if there are missing columns\n",
    "\n",
    "print(df.photoUrl.isna().any())\n",
    "print(df.photoUrl.isnull().any())\n",
    "\n",
    "# we don't have missing columns\n",
    "\n",
    "# Lets preview the values\n",
    "\n",
    "df.photoUrl.head(10)\n",
    "\n",
    "# it looks like they are png files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoUrl</th>\n",
       "      <th>LongName</th>\n",
       "      <th>playerUrl</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>OVA</th>\n",
       "      <th>POT</th>\n",
       "      <th>Team &amp; Contract</th>\n",
       "      <th>...</th>\n",
       "      <th>A/W</th>\n",
       "      <th>D/W</th>\n",
       "      <th>IR</th>\n",
       "      <th>PAC</th>\n",
       "      <th>SHO</th>\n",
       "      <th>PAS</th>\n",
       "      <th>DRI</th>\n",
       "      <th>DEF</th>\n",
       "      <th>PHY</th>\n",
       "      <th>Hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [photoUrl, LongName, playerUrl, Nationality, Positions, Name, Age, OVA, POT, Team & Contract, ID, Height, Weight, foot, BOV, BP, Growth, Joined, Loan Date End, Value, Wage, Release Clause, Attacking, Crossing, Finishing, Heading Accuracy, Short Passing, Volleys, Skill, Dribbling, Curve, FK Accuracy, Long Passing, Ball Control, Movement, Acceleration, Sprint Speed, Agility, Reactions, Balance, Power, Shot Power, Jumping, Stamina, Strength, Long Shots, Mentality, Aggression, Interceptions, Positioning, Vision, Penalties, Composure, Defending, Marking, Standing Tackle, Sliding Tackle, Goalkeeping, GK Diving, GK Handling, GK Kicking, GK Positioning, GK Reflexes, Total Stats, Base Stats, W/F, SM, A/W, D/W, IR, PAC, SHO, PAS, DRI, DEF, PHY, Hits]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 77 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets further check if they are all png files\n",
    "# We want to fetch values that do not end with .png\n",
    "\n",
    "df[df.photoUrl.str[-4:] != \".png\"] \n",
    "\n",
    "# all images are png and good, so we didn't get anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets go ahead and add the photoUrl column to our clean data\n",
    "\n",
    "clean_data['photoUrl'] = pd.Series(df.photoUrl.copy(), dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'i', 'o', 'n', 'e', 'l', ' ', 'M', 's', 'C', '.', 'R', 'a', 'd', 'S', 't', 'A', 'v', 'r', 'J', 'O', 'b', 'k', 'K', 'D', 'B', 'u', 'y', 'N', 'm', 'w', 'p', 'é', 'c', 'h', 'V', 'g', 'j', '-', 'H', 'q', 'T', 'z', 'G', 'í', 'ü', \"'\", 'P', 'E', 'č', 'x', 'F', 'á', 'I', 'W', 'ę', 'Á', 'ć', 'ë', 'Q', 'Y', 'ó', 'Š', 'f', 'Z', 'ê', 'ñ', 'â', 'U', 'ú', 'Ñ', 'Ø', 'à', 'ã', 'š', 'ý', 'İ', 'ğ', 'ž', 'É', 'ř', 'ç', 'ô', 'Ö', 'ï', 'X', 'ö', 'Ł', 'ń', 'Ç', 'ò', 'ø', 'æ', 'Ć', 'ð', 'î', 'Ó', 'Ü', 'ą', 'ä', 'ă', 'ș', 'è', 'Ș', 'ı', 'ł', 'ş', 'ß', 'Ş', 'ū', 'Ō', 'Đ', 'Â', 'ț', 'õ', 'Ř', 'Ž', 'Č', 'å', 'ě', 'đ', 'ō', 'ů', 'ź', 'Ś', 'ā', 'Þ', 'Ż', 'Ț', 'Ľ', 'ż', 'þ', 'ľ', 'Å', 'ś', 'À', 'Í', 'ň', 'ő', 'ķ', '\\xad']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets clean the LongName column\n",
    "\n",
    "# We want to get the unique characters first\n",
    "\n",
    "print(get_unique_characters_in(df, 'LongName'))\n",
    "\n",
    "# there are strange charaters here. And its because there are German, Greek, etc players so it makes sense to have these characters in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702       Miguel Ângelo da Silva Rocha\n",
       "3991       Eulânio Ângelo Chipela Gomes\n",
       "4167           Diego Ângelo de Oliveira\n",
       "4429           Ângelo Pelegrinelli Neto\n",
       "10244    Ângelo Rafael O. Sousa Taveira\n",
       "Name: LongName, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets fetch something using the characters and check on google if its right\n",
    "\n",
    "df['LongName'][df.LongName.str.contains('Â')]\n",
    "\n",
    "# And we can see that these are names of players so that characters ain't strange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The LongName column is good, so let's add it to the clean data\n",
    "\n",
    "clean_data['LongName'] = pd.Series(df.LongName.copy(), dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets handle the playerUrl column\n",
    "# Check if there are missing columns\n",
    "\n",
    "print(df.playerUrl.isnull().any())\n",
    "print(df.playerUrl.isna().any())\n",
    "\n",
    "# we don't have missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 't', 'p', ':', '/', 's', 'o', 'f', 'i', 'a', '.', 'c', 'm', 'l', 'y', 'e', 'r', '1', '5', '8', '0', '2', '3', 'n', '-', 'd', 'v', '9', 'j', 'b', 'k', 'u', '7', '4', 'w', '6', 'g', 'q', 'z', 'x']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We want to get the unique characters first\n",
    "\n",
    "print(get_unique_characters_in(df, 'playerUrl')) \n",
    "\n",
    "# there are no strange characters so lets add it to the clean data\n",
    "\n",
    "clean_data['playerUrl'] = pd.Series(df.playerUrl.copy(), dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets handle the Nationality column\n",
    "# Check if there are missing columns\n",
    "\n",
    "print(df.Nationality.isnull().any())\n",
    "print(df.Nationality.isna().any())\n",
    "\n",
    "# we don't have missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'r', 'g', 'e', 'n', 't', 'i', 'a', 'P', 'o', 'u', 'l', 'S', 'v', 'B', 'm', 'z', 'd', 'F', 'c', 'E', 'y', 'p', 'N', 'h', 's', 'G', 'K', ' ', 'R', 'b', 'C', 'I', 'U', 'w', 'k', 'M', 'D', 'H', 'x', 'W', 'T', 'V', 'f', 'J', 'Z', 'q', 'L', '&', 'ã', 'é', 'í', 'j']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4928    São Tomé & Príncipe\n",
       "Name: Nationality, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# We want to get the unique characters first\n",
    "\n",
    "print(get_unique_characters_in(df, 'Nationality'))\n",
    "\n",
    "# there are some strange characters. Lets investage with a sample\n",
    "\n",
    "df['Nationality'][df.Nationality.str.contains(\"é\")] #okay\n",
    "\n",
    "# the output is good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets add the Nationality to the clean data\n",
    "\n",
    "clean_data['Nationality'] = pd.Series(df.Nationality.copy(), dtype=str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets handle the Positions column\n",
    "# Check if there are missing columns\n",
    "\n",
    "print(df.Positions.isnull().any())\n",
    "print(df.Positions.isna().any())\n",
    "\n",
    "# we don't have missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'W', ' ', 'S', 'T', 'C', 'F', 'L', 'G', 'K', 'A', 'M', 'B', 'D']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We want to get the unique characters first\n",
    "\n",
    "print(get_unique_characters_in(df, 'Positions'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets see the unique values\n",
    "\n",
    "unique_values = df.Positions.unique() # code positions\n",
    "\n",
    "# Lets get the number of unique values here\n",
    "\n",
    "len(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Since the data can be used by anyone for specific objectives, lets create an encoded volumns of the positions\n",
    "# SO that those who want to work with the integer values can, and those who want to use the string or categorical values can also do that\n",
    "\n",
    "counter = 1\n",
    "array_of_position_categoricals = {}\n",
    "\n",
    "for pos in df.Positions.unique():\n",
    "    if pos not in array_of_position_categoricals.keys():\n",
    "        array_of_position_categoricals[pos] = counter\n",
    "        counter+=1\n",
    "    \n",
    "new_pos = df.Positions.copy()\n",
    "\n",
    "new_pos.replace(array_of_position_categoricals, inplace=True)\n",
    "\n",
    "# Lets add the categorical column to the clean data\n",
    "\n",
    "clean_data['Positions Categorical'] = pd.Series(new_pos).astype('int64')\n",
    "\n",
    "# Lets add the column itself to the  clean data\n",
    "\n",
    "clean_data['Positions'] = pd.Series(df.Positions.copy(), dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0           \\n\\n\\n\\nFC Barcelona\\n2004 ~ 2021\\n\\n\n",
       "1               \\n\\n\\n\\nJuventus\\n2018 ~ 2022\\n\\n\n",
       "2        \\n\\n\\n\\nAtlético Madrid\\n2014 ~ 2023\\n\\n\n",
       "3        \\n\\n\\n\\nManchester City\\n2015 ~ 2023\\n\\n\n",
       "4    \\n\\n\\n\\nParis Saint-Germain\\n2017 ~ 2022\\n\\n\n",
       "Name: Team & Contract, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets clean the Team and contract column\n",
    "# This columns is very messy\n",
    "\n",
    "# Lets check if there are missing values\n",
    "\n",
    "print(df['Team & Contract'].isnull().any())\n",
    "print(df['Team & Contract'].isna().any())\n",
    "\n",
    "\n",
    "# Lets preview it\n",
    "df['Team & Contract'].head()\n",
    "\n",
    "# we don't have missing values\n",
    "# AT a glance, you know there's work to be done :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'F', 'C', ' ', 'B', 'a', 'r', 'c', 'e', 'l', 'o', 'n', '2', '0', '4', '~', '1', 'J', 'u', 'v', 't', 's', '8', 'A', 'é', 'i', 'M', 'd', '3', 'h', 'y', '5', 'P', 'S', '-', 'G', 'm', '7', 'ü', 'L', 'p', '6', 'R', '9', 'T', 'H', 'N', 'I', 'D', 'U', 'z', 'ö', 'g', 'b', 'O', 'q', 'V', 'j', 'x', 'f', 'W', 'E', 'ê', 'w', 'k', 'ş', 'K', ',', 'ã', '.', 'Y', 'É', 'Z', '&', 'ç', 'ó', 'ú', 'á', 'Q', 'í', 'î', 'Ç', 'ø', \"'\", 'ñ', 'ň', 'è', 'ğ', 'ł', '/', '(', ')', 'ń', 'ę', 'â', 'å', 'æ', 'Ś', 'ą', 'ä', 'Ö', 'ș']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets get the unique characters\n",
    "\n",
    "print(get_unique_characters_in(df, 'Team & Contract'))\n",
    "\n",
    "# It looks like we have spaces and tilda (~) which is supposed to be a dash (-). Lets replace them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace white spaces and other characters\n",
    "\n",
    "df['Team & Contract'] = df['Team & Contract'].str.replace('\\n','',regex=True) \n",
    "\n",
    "df['Team & Contract'] = df['Team & Contract'].str.replace('~','-',regex=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FC Barcelona2004 - 2021', 'Juventus2018 - 2022',\n",
       "       'Atlético Madrid2014 - 2023', ..., 'Dalian YiFang FC2019 - 2024',\n",
       "       'Henan Jianye FC2020 - 2021', 'Wuhan Zall2018 - 2022'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets get the unique values in the column\n",
    "\n",
    "df['Team & Contract'].unique()\n",
    "\n",
    "# The data looks clean a bit. We still have a lot to do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets seperate the contract initiation year and closing year.\n",
    "# We can use regular expressions for that\n",
    "\n",
    "from_col = [] # contract from\n",
    "to_col = [] # contract to\n",
    "\n",
    "# Pattern\n",
    "pattern = r\"\\d+\\.?\\d*|\\.\\d+\"\n",
    "\n",
    "for row in df['Team & Contract']:\n",
    "    numbers = re.findall(pattern, row)\n",
    "#     print(numbers)\n",
    "    if len(numbers) == 2:\n",
    "        if len(numbers[0]) == 4 and len(numbers[1]) == 4:\n",
    "            from_col.append(numbers[0])\n",
    "            to_col.append(numbers[1])\n",
    "    elif len(numbers) == 3:\n",
    "        if len(numbers[1]) == 4 and len(numbers[2]) == 4:\n",
    "            from_col.append(numbers[1])\n",
    "            to_col.append(numbers[2])\n",
    "            \n",
    "# At this point we have separated the init and closing years into separate lists.\n",
    "# We will add it as a column in the clean data in moments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We only extracted the init and closing contract years.\n",
    "# Lets remover them from the Team information. So that the 3 columns will be independent\n",
    "# Lets leverage regex once more\n",
    "\n",
    "# We're removing all the numbers and replacing the (-) we introduced\n",
    "\n",
    "pattern = r\"\\d+\"\n",
    "\n",
    "df['Team & Contract'] = df['Team & Contract'].str.replace(pattern,\"\")\n",
    "df['Team & Contract'] = df['Team & Contract'].str.replace(\"-\",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>OVA</th>\n",
       "      <th>POT</th>\n",
       "      <th>ID</th>\n",
       "      <th>BOV</th>\n",
       "      <th>Growth</th>\n",
       "      <th>Attacking</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>Finishing</th>\n",
       "      <th>Heading Accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>PHY</th>\n",
       "      <th>photoUrl</th>\n",
       "      <th>LongName</th>\n",
       "      <th>playerUrl</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Positions Categorical</th>\n",
       "      <th>Positions</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Contract From</th>\n",
       "      <th>Contract To</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>158023</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>https://cdn.sofifa.com/players/158/023/21_60.png</td>\n",
       "      <td>Lionel Messi</td>\n",
       "      <td>http://sofifa.com/player/158023/lionel-messi/2...</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>RW ST CF</td>\n",
       "      <td>FC Barcelona</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>20801</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>437</td>\n",
       "      <td>84</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>https://cdn.sofifa.com/players/020/801/21_60.png</td>\n",
       "      <td>C. Ronaldo dos Santos Aveiro</td>\n",
       "      <td>http://sofifa.com/player/20801/c-ronaldo-dos-s...</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>2</td>\n",
       "      <td>ST LW</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  OVA  POT      ID  BOV  Growth  Attacking  Crossing  Finishing  \\\n",
       "0   33   93   93  158023   93       0        429        85         95   \n",
       "1   35   92   92   20801   92       0        437        84         95   \n",
       "\n",
       "   Heading Accuracy  ...  PHY  \\\n",
       "0                70  ...   65   \n",
       "1                90  ...   77   \n",
       "\n",
       "                                           photoUrl  \\\n",
       "0  https://cdn.sofifa.com/players/158/023/21_60.png   \n",
       "1  https://cdn.sofifa.com/players/020/801/21_60.png   \n",
       "\n",
       "                       LongName  \\\n",
       "0                  Lionel Messi   \n",
       "1  C. Ronaldo dos Santos Aveiro   \n",
       "\n",
       "                                           playerUrl  Nationality  \\\n",
       "0  http://sofifa.com/player/158023/lionel-messi/2...    Argentina   \n",
       "1  http://sofifa.com/player/20801/c-ronaldo-dos-s...     Portugal   \n",
       "\n",
       "   Positions Categorical  Positions           Teams  Contract From  \\\n",
       "0                      1   RW ST CF  FC Barcelona           2004.0   \n",
       "1                      2      ST LW      Juventus           2018.0   \n",
       "\n",
       "   Contract To  \n",
       "0       2021.0  \n",
       "1       2022.0  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Its time to add them to the clean data\n",
    "# We now have these 3 columns Teams, Contract From, and Contract To\n",
    "# Hurray!\n",
    "\n",
    "clean_data['Teams'] = pd.Series(df['Team & Contract'], dtype=str)\n",
    "\n",
    "clean_data['Contract From'] = pd.Series(from_col).astype('int64')\n",
    "\n",
    "clean_data['Contract To'] = pd.Series(to_col).astype('int64')\n",
    "\n",
    "clean_data.head(2)\n",
    "\n",
    "# Interesting right??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "['5', \"'\", '7', '\"', '6', '2', '1', '9', '0', '3', '4', '8']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets clean the height\n",
    "# Lets handle the Nationality column\n",
    "# Check if there are missing columns\n",
    "\n",
    "print(df.Height.isnull().any())\n",
    "print(df.Height.isna().any())\n",
    "\n",
    "# we don't have missing values\n",
    "\n",
    "# Lets see the unique characters that make up the entire column\n",
    "\n",
    "print(get_unique_characters_in(df, 'Height'))\n",
    "\n",
    "# The strange characters here are ' and \". Thats because we're dealing with feets and inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5\\'7\"', '6\\'2\"', '5\\'11\"', '5\\'9\"', '6\\'0\"', '5\\'10\"', '6\\'3\"',\n",
       "       '6\\'4\"', '6\\'1\"', '6\\'6\"', '5\\'8\"', '5\\'6\"', '6\\'5\"', '5\\'5\"',\n",
       "       '5\\'4\"', '6\\'7\"', '5\\'2\"', '5\\'3\"', '6\\'8\"', '5\\'1\"', '6\\'9\"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets see the unique columns\n",
    "\n",
    "df.Height.unique()\n",
    "\n",
    "# It seems all values are in feets and inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Since all values are in feets and inches, presented for instance as 6'8\" (6 feets 8 inches), lets replace the ' with a dot and remove the \"\n",
    "# SO we can have 6.8 which means 6 feets 8 inches, and this will run through. It doesn't really matter the data that comes in. It will still hold.\n",
    "# The possible issue is that, someone won't understand what 6.8 is unless we explain. But its fine for now.\n",
    "# We can aswell calculate or convert feets and inches to centimeters\n",
    "\n",
    "df['Height'][df.Height.str.contains(\"'\")]\n",
    "df['Height'] = df.Height.str.replace(\"'\", '.')\n",
    "df['Height'] = df.Height.str.replace('\"', '')\n",
    "\n",
    "# Lets add it to the clean data\n",
    "\n",
    "clean_data['Height'] = pd.Series(df.Height, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets convert the heights to centimeters and include it as a new column\n",
    "\n",
    "heights_in_cm = []\n",
    "\n",
    "for height in df.Height:\n",
    "    height =  height.split('.')\n",
    "    feets, inches = int(height[0]), int(height[1])\n",
    "   \n",
    "    # convert feet to cm: 1 feet = 30.48 cm [source: https://tinyurl.com/ykth4wed]\n",
    "    feets_to_cm = feets * 30.48\n",
    "    # convert inches to cm: 1 inch = 2.54cm [source: https://tinyurl.com/ykth4wed]\n",
    "    inche_to_cm = inches * 2.54\n",
    "    \n",
    "    heights_in_cm.append( round(float(feets_to_cm + inche_to_cm),2) )\n",
    "      \n",
    "# Lets add the height in cm to the clean data now\n",
    "# Hope you get it!\n",
    "\n",
    "clean_data['Height (cm)'] = pd.Series(heights_in_cm, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Height (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.70</td>\n",
       "      <td>170.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.20</td>\n",
       "      <td>187.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.20</td>\n",
       "      <td>187.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.11</td>\n",
       "      <td>180.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.90</td>\n",
       "      <td>175.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Height (cm)\n",
       "0    5.70       170.18\n",
       "1    6.20       187.96\n",
       "2    6.20       187.96\n",
       "3    5.11       180.34\n",
       "4    5.90       175.26"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets preview the clean heights\n",
    "\n",
    "clean_data[['Height', 'Height (cm)']].head()\n",
    "\n",
    "# 5'7 = 170.18 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "['1', '5', '9', 'l', 'b', 's', '8', '3', '2', '4', '0', '7', '6']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets clean the Weight\n",
    "# Lets handle the Weight column\n",
    "# Check if there are missing columns\n",
    "\n",
    "print(df.Weight.isnull().any())\n",
    "print(df.Weight.isna().any())\n",
    "\n",
    "# There are no missing values\n",
    "\n",
    "# Lets now check the unique characters\n",
    "\n",
    "print(get_unique_characters_in(df, 'Weight'))\n",
    "\n",
    "# It looks like we have some string in there. Lets quickly replace them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace all lbs\n",
    "\n",
    "df['Weight'] = df.Weight.str.replace(\"lbs\", '')\n",
    "\n",
    "# Save to clean data\n",
    "\n",
    "clean_data['Weight'] = df.Weight.astype('int64').copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the foot\n",
    "# Lets handle the foot column\n",
    "\n",
    "print(df.foot.isnull().any())\n",
    "print(df.foot.isna().any())\n",
    "\n",
    "# We don't have nulls\n",
    "\n",
    "# Lets get the unique items\n",
    "\n",
    "df.foot.unique()\n",
    "\n",
    "# It seems we have just Left and Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets create a categorical data out of this and add to the clean data\n",
    "\n",
    "clean_data['foot_categorical'] = df.foot.copy().replace({'Left':1,'Right':2}).astype('int64')\n",
    "\n",
    "clean_data['foot'] = pd.Series(df.foot, dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets clean the BP\n",
    "# Lets handle the BP column\n",
    "\n",
    "df.BP.isna().any()\n",
    "\n",
    "df.BP.isnull().any()\n",
    "\n",
    "# There are no missing values\n",
    "\n",
    "# Lets get the unique characters\n",
    "\n",
    "print(get_unique_characters_in(df, 'BP')) # it looks clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get the unique values\n",
    "\n",
    "df.BP.unique()\n",
    "\n",
    "# There's an opportunity for categorical column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets create the categoricla column as we used to\n",
    "\n",
    "counter = 1\n",
    "\n",
    "bp_categoricals = {}\n",
    "\n",
    "for _bp in df.BP.unique():\n",
    "    if _bp not in bp_categoricals.keys():\n",
    "        bp_categoricals[_bp] = counter\n",
    "        counter+=1\n",
    "\n",
    "# lets replace the newly created indexes\n",
    "new_bp = df.BP.copy()\n",
    "new_bp.replace(bp_categoricals, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Lets add them to the clean data\n",
    "clean_data['BP'] = pd.Series(df.BP, dtype=str)\n",
    "clean_data['BP Categorical'] = pd.Series(new_bp).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets clean the Joined\n",
    "# Lets handle the Joined column\n",
    "# Check if there are missing values\n",
    "\n",
    "df.Joined.isna().any()\n",
    "df.Joined.isnull().any()\n",
    "\n",
    "# There are no missing values\n",
    "\n",
    "# Lets check the data type because this is supposed to be date\n",
    "\n",
    "df.Joined.dtype\n",
    "\n",
    "# It turned out to be an object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets enforce some datatypes here and add it to the clean data\n",
    "\n",
    "clean_data['Joined'] = pd.to_datetime( df.Joined ).dt.date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets clean the loan date\n",
    "# Lets handle the loan data column\n",
    "\n",
    "df['Loan Date End'].isna().any()\n",
    "\n",
    "# there are some issues. Lets investigate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets check how many are empty\n",
    "\n",
    "df['Loan Date End'].isnull().sum()\n",
    "\n",
    "# we have 17965. This means some players are not on loan so we can remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In that case, lets just enforce the datatypes and create a new column which indicates whether a player is on loan or not\n",
    "# Interestin right?\n",
    "\n",
    "df['Loan Date End'].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert column to dates\n",
    "\n",
    "loan_date_end = pd.to_datetime( df['Loan Date End'] ).dt.date\n",
    "\n",
    "# make a copy of the copy\n",
    "\n",
    "loan_date_end_copy = loan_date_end\n",
    "\n",
    "# fill missing values with 0. This will help is determining who's on loan\n",
    "loan_date_end_copy = loan_date_end_copy.fillna(0)\n",
    "\n",
    "# create a new column which indicates whether a player is on loan. This will be a justification to why some columns in the Loan Date End is NaT\n",
    "clean_data['Is On Loan'] = pd.Series(loan_date_end_copy.apply(lambda x: 1 if x != 0 else 0), dtype=int)\n",
    "\n",
    "clean_data['Loan Date End'] = loan_date_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the Value\n",
    "# Lets handle the Value column\n",
    "# Check if there are missing values\n",
    "\n",
    "df.Value.isna().any()\n",
    "df.Value.isnull().any()\n",
    "\n",
    "# There are no issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get the unique characters that make up this column\n",
    "\n",
    "print(get_unique_characters_in(df, 'Value'))\n",
    "\n",
    "# We have M = million, K = thousand and the currency. Lets handle them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets replace the currency first\n",
    "\n",
    "df.Value = df.Value.str.replace('€','')\n",
    "\n",
    "# We will convert the M to million by multiplying by 1,000,000 and 1,000 in the case of K\n",
    "new_values = []\n",
    "\n",
    "for val in df.Value:\n",
    "    if 'M' in val:\n",
    "        raw_figure = float(val.split('M')[0])\n",
    "        new_values.append(raw_figure*1000000)\n",
    "    \n",
    "    elif 'K' in val:\n",
    "        raw_figure = float(val.split('K')[0])\n",
    "        new_values.append(raw_figure*1000)\n",
    "        \n",
    "    else:\n",
    "        new_values.append(val)\n",
    "\n",
    "# Lets add it to the clean data\n",
    "clean_data['Value'] = pd.Series(new_values, dtype=float)\n",
    "clean_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets handle the wages like we did for the Value\n",
    "\n",
    "print(get_unique_characters_in(df, 'Wage'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.Wage = df.Wage.str.replace('€','')\n",
    "\n",
    "new_values = []\n",
    "\n",
    "for val in df.Wage:\n",
    "    if 'M' in val:\n",
    "        raw_figure = float(val.split('M')[0])\n",
    "        new_values.append(raw_figure*1000000)\n",
    "    \n",
    "    elif 'K' in val:\n",
    "        raw_figure = float(val.split('K')[0])\n",
    "        new_values.append(raw_figure*1000)\n",
    "        \n",
    "    else:\n",
    "        new_values.append(val)\n",
    "        \n",
    "clean_data['Wage'] = pd.Series(new_values, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets handle the release clause like we did for the Value\n",
    "\n",
    "print(get_unique_characters_in(df, 'Release Clause'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Release Clause'] = df['Release Clause'].str.replace('€','')\n",
    "\n",
    "new_values = []\n",
    "\n",
    "for val in df['Release Clause']:\n",
    "    if 'M' in val:\n",
    "        raw_figure = float(val.split('M')[0])\n",
    "        new_values.append(raw_figure*1000000)\n",
    "    \n",
    "    elif 'K' in val:\n",
    "        raw_figure = float(val.split('K')[0])\n",
    "        new_values.append(raw_figure*1000)\n",
    "        \n",
    "    else:\n",
    "        new_values.append(val)\n",
    "        \n",
    "clean_data['Release Clause'] = pd.Series(new_values, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the w/f columns\n",
    "# Lets check if there are missing values\n",
    "\n",
    "df['W/F'].isna().any()\n",
    "df['W/F'].isnull().any()\n",
    "\n",
    "# There are no missing values\n",
    "# Lets go ahead and get the unique values\n",
    "\n",
    "df['W/F'].unique()\n",
    "\n",
    "# These are stars, lets deal with it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# There are some stars here. Lets deal with it in two ways\n",
    "# 1. Lets remove the stars and leave the integers standing alone\n",
    "# 2 Lets multiple the stars by the integers and store them.\n",
    "\n",
    "stars = {}\n",
    "numbers = []\n",
    "\n",
    "for star in df['W/F']:\n",
    "    number_of_stars = int(star.split(' ★')[0])\n",
    "    stars[star] = number_of_stars * '★'\n",
    "    numbers.append(int(number_of_stars))\n",
    "\n",
    "copy_of_stars_column = df['W/F'].copy()\n",
    "copy_of_stars_column.replace(stars, inplace=True)\n",
    "\n",
    "# Lets add them to the clean data\n",
    "\n",
    "clean_data['W/F Stars'] = copy_of_stars_column\n",
    "clean_data['W/F'] = pd.Series(numbers, dtype=int)\n",
    "clean_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SM column is like the W/F column. Lets use same approach to deal with it\n",
    "\n",
    "df['SM'].isna().any()\n",
    "df['SM'].isnull().any()\n",
    "\n",
    "df['SM'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stars = {}\n",
    "numbers = []\n",
    "\n",
    "for star in df['SM']:\n",
    "    number_of_stars = int(star.split('★')[0])\n",
    "    stars[star] = number_of_stars * '★'\n",
    "    numbers.append(int(number_of_stars))\n",
    "\n",
    "copy_of_stars_column = df['SM'].copy()\n",
    "copy_of_stars_column.replace(stars, inplace=True)\n",
    "\n",
    "clean_data['SM Stars'] = copy_of_stars_column\n",
    "clean_data['SM'] =pd.Series(numbers, dtype=int)\n",
    "clean_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets handle to A/W column\n",
    "# Lets check for missing values\n",
    "\n",
    "df['A/W'].isna().any()\n",
    "df['A/W'].isnull().any()\n",
    "\n",
    "# We dont have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get the unique characters\n",
    "\n",
    "print(get_unique_characters_in(df, 'A/W'))\n",
    "\n",
    "# Good, we don't have strange characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get the unique vakues\n",
    "\n",
    "df['A/W'].unique()\n",
    "\n",
    "# You remember?? There's an opportunity for categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 1\n",
    "\n",
    "aw_categoricals = {}\n",
    "\n",
    "for aw in df['A/W'].unique():\n",
    "    if aw not in aw_categoricals.keys():\n",
    "        aw_categoricals[aw] = counter\n",
    "        counter+=1\n",
    "    \n",
    "new_aw = df['A/W'].copy()\n",
    "new_aw.replace(aw_categoricals, inplace=True)\n",
    "\n",
    "# Lets add both the clean and categorical column we just created to the clean data\n",
    "\n",
    "clean_data['A/W'] = pd.Series(df['A/W'], dtype=str)\n",
    "clean_data['A/W Categorical'] = pd.Series(new_aw).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(get_unique_characters_in(df, 'D/W'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets clean the D/W columns\n",
    "# Lets check for missing values\n",
    "\n",
    "df['D/W'].isna().any()\n",
    "df['D/W'].isnull().any()\n",
    "\n",
    "# There are no issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get the unique values\n",
    "\n",
    "df['D/W'].unique()\n",
    "\n",
    "# There's an opportunity for categorical column as usual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 1\n",
    "\n",
    "dw_categoricals = {}\n",
    "\n",
    "for dw in df['D/W'].unique():\n",
    "    if dw not in dw_categoricals.keys():\n",
    "        dw_categoricals[dw] = counter\n",
    "        counter+=1\n",
    "    \n",
    "new_dw = df['D/W'].copy()\n",
    "new_dw.replace(dw_categoricals, inplace=True)\n",
    "\n",
    "# You get this right??\n",
    "# We meuve\n",
    "\n",
    "clean_data['D/W'] = pd.Series(df['D/W'], dtype=str)\n",
    "clean_data['D/W Categorical'] = pd.Series(new_dw).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the IR columns\n",
    "# Its similar to the D/W\n",
    "# Lets check for missing vlaues\n",
    "\n",
    "df['IR'].isna().any()\n",
    "df['IR'].isnull().any()\n",
    "\n",
    "# There are no issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get the unique values\n",
    "\n",
    "df.IR.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = {}\n",
    "numbers = []\n",
    "\n",
    "for star in df.IR:\n",
    "    number_of_stars = int(star.split(' ★')[0])\n",
    "    stars[star] = number_of_stars * '★'\n",
    "    numbers.append(int(number_of_stars))\n",
    "\n",
    "copy_of_stars_column = df.IR.copy()\n",
    "copy_of_stars_column.replace(stars, inplace=True)\n",
    "\n",
    "# Just like how we do it...lets do it again\n",
    "\n",
    "clean_data['IR Stars'] = copy_of_stars_column\n",
    "clean_data['IR'] = pd.Series(numbers, dtype=int)\n",
    "clean_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets clean the Hits column\n",
    "\n",
    "df.Hits.isna().any()\n",
    "df.Hits.isnull().any()\n",
    "\n",
    "# no issues found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.Hits.unique()\n",
    "\n",
    "# Eish, it looks like ther are issues here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get the unique characters that make up the column\n",
    "\n",
    "print(get_unique_characters_in(df, 'Hits'))\n",
    "\n",
    "# It seems we have spaces and thousands (K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get the unique vlaues\n",
    "\n",
    "df.Hits.unique()\n",
    "\n",
    "# this is really messy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets clean it\n",
    "\n",
    "hits = []\n",
    "\n",
    "for hit in df.Hits:\n",
    "    \n",
    "    checked = \"\"\n",
    "    \n",
    "    # Checks and deal with integers\n",
    "    if type(hit) != str:\n",
    "        checked = result\n",
    "    \n",
    "    # Checks and deal with string...they have the white spaces\n",
    "    else:\n",
    "        result = hit.strip()\n",
    "        checked = result\n",
    "        \n",
    "    # Handle the thousands\n",
    "    if \"K\" in str(checked):\n",
    "        result = checked.replace(\"K\",'')\n",
    "        result = float(result) * 1000\n",
    "        hits.append(result)\n",
    "    else:\n",
    "        result = float(checked)\n",
    "        hits.append(result)\n",
    "\n",
    "# Add it to the clean columns\n",
    "clean_data['Hits'] = pd.Series(hits, dtype=float)\n",
    "\n",
    "# Finally, lets remove missing values using all columns except Loan Date End because most players are not on loan so that field has a lot of missing values\n",
    "\n",
    "clean_data.dropna(subset=clean_data.columns.difference(['Loan Date End']), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Congratulations!\n",
    "# We're done cleaning this data\n",
    "# Lets check this last thing\n",
    "\n",
    "# Why not look at our clean data to be sure if everything is fine??\n",
    "# It makes sense, isn't it??\n",
    "\n",
    "clean_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
